{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9befceb4",
   "metadata": {},
   "source": [
    "# IMPORT LIBRARIES AND SET CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfe56ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH  = Path('../data')\n",
    "PROCESSED_DATA_PATH = DATA_PATH / 'processed'\n",
    "\n",
    "VAR_LIST_FILE_PATH = Path('../documentation/var_list_decription.txt')\n",
    "PROCESSED_FILE_PATH_CSV = PROCESSED_DATA_PATH / 'converted_from_script_new02.csv'\n",
    "\n",
    "FINAL_FILE_PATH = PROCESSED_DATA_PATH / 'final_data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcc2394",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "The original script overviewed data with pandas .info() and .head(). Since pandas is disallowed, we will skip directly to processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "909d4370",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_VAR_NAMES = [\n",
    "    \"State\",\n",
    "    \"Sex\",\n",
    "    \"GeneralHealth\",\n",
    "    \"PhysicalHealthDays\",\n",
    "    \"MentalHealthDays\",\n",
    "    \"LastCheckupTime\",\n",
    "    \"PhysicalActivities\",\n",
    "    \"SleepHours\",\n",
    "    \"RemovedTeeth\",\n",
    "    \"HadHeartAttack\",\n",
    "    \"HadAngina\",\n",
    "    \"HadStroke\",\n",
    "    \"HadAsthma\",\n",
    "    \"HadSkinCancer\",\n",
    "    \"HadCOPD\",\n",
    "    \"HadDepressiveDisorder\",\n",
    "    \"HadKidneyDisease\",\n",
    "    \"HadArthritis\",\n",
    "    \"HadDiabetes\",\n",
    "    \"DeafOrHardOfHearing\",\n",
    "    \"BlindOrVisionDifficulty\",\n",
    "    \"DifficultyConcentrating\",\n",
    "    \"DifficultyWalking\",\n",
    "    \"DifficultyDressingBathing\",\n",
    "    \"DifficultyErrands\",\n",
    "    \"SmokerStatus\",\n",
    "    \"ECigaretteUsage\",\n",
    "    \"ChestScan\",\n",
    "    \"RaceEthnicityCategory\",\n",
    "    \"AgeCategory\",\n",
    "    \"HeightInMeters\",\n",
    "    \"WeightInKilograms\",\n",
    "    \"BMI\",\n",
    "    \"AlcoholDrinkers\",\n",
    "    \"HIVTesting\",\n",
    "    \"FluVaxLast12\",\n",
    "    \"PneumoVaxEver\",\n",
    "    \"TetanusLast10Tdap\",\n",
    "    \"HighRiskLastYear\",\n",
    "    \"CovidPos\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f8d22a",
   "metadata": {},
   "source": [
    "### Load Variable List (without Pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38d8aacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 40 variables to keep.\n",
      "['_STATE', 'SEXVAR', 'GENHLTH', 'PHYSHLTH', 'MENTHLTH', 'CHECKUP1', 'EXERANY2', 'SLEPTIM1', 'RMVTETH4', 'CVDINFR4', 'CVDCRHD4', 'CVDSTRK3', 'ASTHMA3', 'CHCSCNC1', 'CHCCOPD3', 'ADDEPEV3', 'CHCKDNY2', 'HAVARTH4', 'DIABETE4', 'DEAF', 'BLIND', 'DECIDE', 'DIFFWALK', 'DIFFDRES', 'DIFFALON', '_SMOKER3', 'ECIGNOW2', 'LCSCTSC1', '_RACEGR4', '_AGEG5YR', 'HTM4', 'WTKG3', '_BMI5', 'DRNKANY6', '_AIDTST4', 'FLUSHOT7', 'PNEUVAC4', 'TETANUS1', 'HIVRISK5', 'COVIDPOS']\n"
     ]
    }
   ],
   "source": [
    "var_list = []\n",
    "try:\n",
    "    with open(VAR_LIST_FILE_PATH, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if ' - ' in line:\n",
    "                var_name = line.split(' - ', 1)[0].strip()\n",
    "                var_list.append(var_name)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {VAR_LIST_FILE_PATH} was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while reading {VAR_LIST_FILE_PATH}: {e}\")\n",
    "\n",
    "print(f\"Loaded {len(var_list)} variables to keep.\")\n",
    "print(var_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e2b0c1",
   "metadata": {},
   "source": [
    "### Define All Transformation Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1fc3926",
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE = {\n",
    "    1: \"Alabama\",\n",
    "    2: \"Alaska\",\n",
    "    4: \"Arizona\",\n",
    "    5: \"Arkansas\",\n",
    "    6: \"California\",\n",
    "    8: \"Colorado\",\n",
    "    9: \"Connecticut\",\n",
    "    10: \"Delaware\",\n",
    "    11: \"District of Columbia\",\n",
    "    12: \"Florida\",\n",
    "    13: \"Georgia\",\n",
    "    15: \"Hawaii\",\n",
    "    16: \"Idaho\",\n",
    "    17: \"Illinois\",\n",
    "    18: \"Indiana\",\n",
    "    19: \"Iowa\",\n",
    "    20: \"Kansas\",\n",
    "    21: \"Kentucky\",\n",
    "    22: \"Louisiana\",\n",
    "    23: \"Maine\",\n",
    "    24: \"Maryland\",\n",
    "    25: \"Massachusetts\",\n",
    "    26: \"Michigan\",\n",
    "    27: \"Minnesota\",\n",
    "    28: \"Mississippi\",\n",
    "    29: \"Missouri\",\n",
    "    30: \"Montana\",\n",
    "    31: \"Nebraska\",\n",
    "    32: \"Nevada\",\n",
    "    33: \"New Hampshire\",\n",
    "    34: \"New Jersey\",\n",
    "    35: \"New Mexico\",\n",
    "    36: \"New York\",\n",
    "    37: \"North Carolina\",\n",
    "    38: \"North Dakota\",\n",
    "    39: \"Ohio\",\n",
    "    40: \"Oklahoma\",\n",
    "    41: \"Oregon\",\n",
    "    42: \"Pennsylvania\",\n",
    "    44: \"Rhode Island\",\n",
    "    45: \"South Carolina\",\n",
    "    46: \"South Dakota\",\n",
    "    47: \"Tennessee\",\n",
    "    48: \"Texas\",\n",
    "    49: \"Utah\",\n",
    "    50: \"Vermont\",\n",
    "    51: \"Virginia\",\n",
    "    53: \"Washington\",\n",
    "    54: \"West Virginia\",\n",
    "    55: \"Wisconsin\",\n",
    "    56: \"Wyoming\",\n",
    "    66: \"Guam\",\n",
    "    72: \"Puerto Rico\",\n",
    "    78: \"Virgin Islands\"\n",
    "}\n",
    "\n",
    "SEX = {1: 'Male', 2: 'Female'}\n",
    "\n",
    "GEN_HEALTH = {\n",
    "    1: \"Excellent\",\n",
    "    2: \"Very good\",\n",
    "    3: \"Good\",\n",
    "    4: \"Fair\",\n",
    "    5: \"Poor\"\n",
    "}\n",
    "\n",
    "PHYS_MEN_HEALTH = {77.0: np.nan,\n",
    "               88.0: 0.0,\n",
    "               99.0: np.nan\n",
    "                  }\n",
    "\n",
    "LAST_CHECKUP = {\n",
    "    1: \"Within past year (anytime less than 12 months ago)\",\n",
    "    2: \"Within past 2 years (1 year but less than 2 years ago)\",\n",
    "    3: \"Within past 5 years (2 years but less than 5 years ago)\",\n",
    "    4: \"5 or more years ago\"\n",
    "}\n",
    "\n",
    "YES_NO_QUESTIONS = {1: 'Yes', 2: 'No'}\n",
    "\n",
    "SLEEP_TIME = lambda x: np.nan if x > 24 else x\n",
    "\n",
    "TEETH_REMOVED = {\n",
    "    1: \"1 to 5\",\n",
    "    2: \"6 or more (but not all)\",\n",
    "    3: \"All\",\n",
    "    8: \"None of them\"\n",
    "}\n",
    "\n",
    "DIABETES = {\n",
    "    1: \"Yes\",\n",
    "    2: \"Yes (but only during pregnancy - female)\",\n",
    "    3: \"No\",\n",
    "    4: \"No (pre-diabetes or borderline diabetes)\",\n",
    "}\n",
    "\n",
    "SMOKER_STATUS = {\n",
    "    1: \"Current smoker - now smokes every day\",\n",
    "    2: \"Current smoker - now smokes some days\",\n",
    "    3: \"Former smoker\",\n",
    "    4: \"Never smoked\"\n",
    "}\n",
    "\n",
    "ECIGARETTES = {\n",
    "    1: \"Never used e-cigarettes in my entire life\",\n",
    "    2: \"Use them every day\",\n",
    "    3: \"Use them some days\",\n",
    "    4: \"Not at all (right now)\"\n",
    "}\n",
    "\n",
    "RACE = {\n",
    "    1: \"White only (Non-Hispanic)\",\n",
    "    2: \"Black only (Non-Hispanic)\",\n",
    "    3: \"Other race only (Non-Hispanic)\",\n",
    "    4: \"Multiracial (Non-Hispanic)\",\n",
    "    5: \"Hispanic\"\n",
    "}\n",
    "\n",
    "AGE_CATEGORY = {\n",
    "    1: \"Age 18 to 24\",\n",
    "    2: \"Age 25 to 29\",\n",
    "    3: \"Age 30 to 34\",\n",
    "    4: \"Age 35 to 39\",\n",
    "    5: \"Age 40 to 44\",\n",
    "    6: \"Age 45 to 49\",\n",
    "    7: \"Age 50 to 54\",\n",
    "    8: \"Age 55 to 59\",\n",
    "    9: \"Age 60 to 64\",\n",
    "    10: \"Age 65 to 69\",\n",
    "    11: \"Age 70 to 74\",\n",
    "    12: \"Age 75 to 79\",\n",
    "    13: \"Age 80 or older\"\n",
    "}\n",
    "\n",
    "TETANUS = {\n",
    "    1: \"Yes - received Tdap\",\n",
    "    2: \"Yes - received tetanus shot, but not Tdap\",\n",
    "    3: \"Yes - received tetanus shot but not sure what type\",\n",
    "    4: \"No - did not receive any tetanus shot in the past 10 years\",\n",
    "}\n",
    "\n",
    "COVID = {\n",
    "    1: \"Yes\",\n",
    "    2: \"No\",\n",
    "    3: \"Tested positive using home test without a health professional\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e8f1g2",
   "metadata": {},
   "source": [
    "### Define Helper Functions for Row Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "h6g9a2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping of new column names to their index (0, 1, 2, ...)\n",
    "NEW_COL_INDICES = {name: i for i, name in enumerate(NEW_VAR_NAMES)}\n",
    "\n",
    "# --- Helper functions to safely convert values ---\n",
    "def safe_float(value):\n",
    "    \"\"\"Converts a value to float, returning np.nan on failure.\"\"\"\n",
    "    try:\n",
    "        return float(value)\n",
    "    except (ValueError, TypeError):\n",
    "        return np.nan\n",
    "\n",
    "def safe_int(value):\n",
    "    \"\"\"Converts a value to int (via float), returning np.nan on failure.\"\"\"\n",
    "    try:\n",
    "        return int(float(value))\n",
    "    except (ValueError, TypeError):\n",
    "        return np.nan\n",
    "\n",
    "# --- Transformation functions for each column ---\n",
    "# These functions modify the row list in-place.\n",
    "\n",
    "def transform_state(row):\n",
    "    idx = NEW_COL_INDICES['State']\n",
    "    val_int = safe_int(row[idx])\n",
    "    row[idx] = STATE.get(val_int, np.nan)\n",
    "\n",
    "def transform_sex(row):\n",
    "    idx = NEW_COL_INDICES['Sex']\n",
    "    val_int = safe_int(row[idx])\n",
    "    row[idx] = SEX.get(val_int, np.nan)\n",
    "\n",
    "def transform_gen_health(row):\n",
    "    idx = NEW_COL_INDICES['GeneralHealth']\n",
    "    val_int = safe_int(row[idx])\n",
    "    row[idx] = GEN_HEALTH.get(val_int, np.nan)\n",
    "\n",
    "def transform_phys_health(row):\n",
    "    idx = NEW_COL_INDICES['PhysicalHealthDays']\n",
    "    val_float = safe_float(row[idx])\n",
    "    # Use .get() to replace 77/88/99, otherwise keep the original value\n",
    "    row[idx] = PHYS_MEN_HEALTH.get(val_float, val_float)\n",
    "\n",
    "def transform_ment_health(row):\n",
    "    idx = NEW_COL_INDICES['MentalHealthDays']\n",
    "    val_float = safe_float(row[idx])\n",
    "    row[idx] = PHYS_MEN_HEALTH.get(val_float, val_float)\n",
    "\n",
    "def transform_checkup(row):\n",
    "    idx = NEW_COL_INDICES['LastCheckupTime']\n",
    "    val_int = safe_int(row[idx])\n",
    "    row[idx] = LAST_CHECKUP.get(val_int, np.nan)\n",
    "\n",
    "def transform_sleep(row):\n",
    "    idx = NEW_COL_INDICES['SleepHours']\n",
    "    val_float = safe_float(row[idx])\n",
    "    row[idx] = SLEEP_TIME(val_float)\n",
    "\n",
    "def transform_teeth(row):\n",
    "    idx = NEW_COL_INDICES['RemovedTeeth']\n",
    "    val_int = safe_int(row[idx])\n",
    "    row[idx] = TEETH_REMOVED.get(val_int, np.nan)\n",
    "\n",
    "def transform_diabetes(row):\n",
    "    idx = NEW_COL_INDICES['HadDiabetes']\n",
    "    val_int = safe_int(row[idx])\n",
    "    row[idx] = DIABETES.get(val_int, np.nan)\n",
    "\n",
    "def transform_smoker(row):\n",
    "    idx = NEW_COL_INDICES['SmokerStatus']\n",
    "    val_int = safe_int(row[idx])\n",
    "    row[idx] = SMOKER_STATUS.get(val_int, np.nan)\n",
    "\n",
    "def transform_ecig(row):\n",
    "    idx = NEW_COL_INDICES['ECigaretteUsage']\n",
    "    val_int = safe_int(row[idx])\n",
    "    row[idx] = ECIGARETTES.get(val_int, np.nan)\n",
    "\n",
    "def transform_race(row):\n",
    "    idx = NEW_COL_INDICES['RaceEthnicityCategory']\n",
    "    val_int = safe_int(row[idx])\n",
    "    row[idx] = RACE.get(val_int, np.nan)\n",
    "\n",
    "def transform_age(row):\n",
    "    idx = NEW_COL_INDICES['AgeCategory']\n",
    "    val_int = safe_int(row[idx])\n",
    "    row[idx] = AGE_CATEGORY.get(val_int, np.nan)\n",
    "\n",
    "def transform_height(row):\n",
    "    idx = NEW_COL_INDICES['HeightInMeters']\n",
    "    val_float = safe_float(row[idx])\n",
    "    row[idx] = val_float / 100 if not np.isnan(val_float) else np.nan\n",
    "\n",
    "def transform_weight(row):\n",
    "    idx = NEW_COL_INDICES['WeightInKilograms']\n",
    "    val_float = safe_float(row[idx])\n",
    "    row[idx] = val_float / 100 if not np.isnan(val_float) else np.nan\n",
    "\n",
    "def transform_bmi(row):\n",
    "    idx = NEW_COL_INDICES['BMI']\n",
    "    val_float = safe_float(row[idx])\n",
    "    row[idx] = val_float / 100 if not np.isnan(val_float) else np.nan\n",
    "\n",
    "def transform_tetanus(row):\n",
    "    idx = NEW_COL_INDICES['TetanusLast10Tdap']\n",
    "    val_int = safe_int(row[idx])\n",
    "    row[idx] = TETANUS.get(val_int, np.nan)\n",
    "\n",
    "def transform_covid(row):\n",
    "    idx = NEW_COL_INDICES['CovidPos']\n",
    "    val_int = safe_int(row[idx])\n",
    "    row[idx] = COVID.get(val_int, np.nan)\n",
    "\n",
    "# Create functions for all Yes/No questions\n",
    "def create_yes_no_transformer(col_name):\n",
    "    \"\"\"Factory to create a mapping function for any Yes/No column.\"\"\"\n",
    "    def transformer(row):\n",
    "        idx = NEW_COL_INDICES[col_name]\n",
    "        val_int = safe_int(row[idx])\n",
    "        row[idx] = YES_NO_QUESTIONS.get(val_int, np.nan)\n",
    "    return transformer\n",
    "\n",
    "yes_no_cols = [\n",
    "    'PhysicalActivities', 'HadHeartAttack', 'HadAngina', 'HadStroke', \n",
    "    'HadAsthma', 'HadSkinCancer', 'HadCOPD', 'HadDepressiveDisorder', \n",
    "    'HadKidneyDisease', 'HadArthritis', 'DeafOrHardOfHearing', \n",
    "    'BlindOrVisionDifficulty', 'DifficultyConcentrating', 'DifficultyWalking', \n",
    "    'DifficultyDressingBathing', 'DifficultyErrands', 'ChestScan', \n",
    "    'AlcoholDrinkers', 'HIVTesting', 'FluVaxLast12', 'PneumoVaxEver', \n",
    "    'HighRiskLastYear'\n",
    "]\n",
    "\n",
    "# List of all transformation functions to apply to each row\n",
    "MASTER_TRANSFORM_LIST = [\n",
    "    transform_state,\n",
    "    transform_sex,\n",
    "    transform_gen_health,\n",
    "    transform_phys_health,\n",
    "    transform_ment_health,\n",
    "    transform_checkup,\n",
    "    transform_sleep,\n",
    "    transform_teeth,\n",
    "    transform_diabetes,\n",
    "    transform_smoker,\n",
    "    transform_ecig,\n",
    "    transform_race,\n",
    "    transform_age,\n",
    "    transform_height,\n",
    "    transform_weight,\n",
    "    transform_bmi,\n",
    "    transform_tetanus,\n",
    "    transform_covid\n",
    "] + [create_yes_no_transformer(col) for col in yes_no_cols]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a2c5d8",
   "metadata": {},
   "source": [
    "### Process and Save the Final File\n",
    "\n",
    "This cell performs the main work:\n",
    "1.  Opens the input and output files.\n",
    "2.  Reads the input header to build an index map.\n",
    "3.  Writes the new header (`NEW_VAR_NAMES`) to the output file.\n",
    "4.  Loops through every row in the large input file.\n",
    "5.  Filters each row to keep only the columns in `var_list`.\n",
    "6.  Applies all transformations to the filtered row.\n",
    "7.  Checks for any `NaN` values (replicating `dropna()`).\n",
    "8.  If no `NaN`s are found, writes the fully processed row to the final file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e197a5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing started...\n",
      "Processed 100000 rows...\n",
      "Processed 200000 rows...\n",
      "Processed 300000 rows...\n",
      "Processed 400000 rows...\n",
      "Processing complete. Wrote 246022 valid rows to ..\\data\\processed\\final_data.csv\n"
     ]
    }
   ],
   "source": [
    "def process_and_write():\n",
    "    print(\"Processing started...\")\n",
    "    rows_written = 0\n",
    "    rows_read = 0\n",
    "    \n",
    "    try:\n",
    "        with open(PROCESSED_FILE_PATH_CSV, mode='r', encoding='utf-8') as infile, \\\n",
    "             open(FINAL_FILE_PATH, mode='w', encoding='utf-8', newline='') as outfile:\n",
    "            \n",
    "            reader = csv.reader(infile)\n",
    "            writer = csv.writer(outfile)\n",
    "            \n",
    "            # 1. Read the original header\n",
    "            original_header = next(reader)\n",
    "            \n",
    "            # 2. Create a map of {column_name: index} from the original file\n",
    "            header_map = {name: i for i, name in enumerate(original_header)}\n",
    "            \n",
    "            # 3. Get the list of *indices* to keep, in the correct order\n",
    "            try:\n",
    "                indices_to_keep = [header_map[name] for name in var_list]\n",
    "            except KeyError as e:\n",
    "                print(f\"Error: Column {e} not found in the input CSV. Aborting.\")\n",
    "                return\n",
    "            \n",
    "            # 4. Write the NEW header to the output file\n",
    "            writer.writerow(NEW_VAR_NAMES)\n",
    "            \n",
    "            # 5. Process each row\n",
    "            for row in reader:\n",
    "                rows_read += 1\n",
    "                if rows_read % 100000 == 0:\n",
    "                    print(f\"Processed {rows_read} rows...\")\n",
    "                \n",
    "                # 6. Filter the row to only the columns we want\n",
    "                # Use list() to create a new copy of the data\n",
    "                processed_row = [row[i] for i in indices_to_keep]\n",
    "                \n",
    "                # 7. Apply all transformations in-place\n",
    "                for transform_func in MASTER_TRANSFORM_LIST:\n",
    "                    transform_func(processed_row)\n",
    "                \n",
    "                # 8. Replicate dropna() - check for any NaN/None values\n",
    "                has_nan = False\n",
    "                for val in processed_row:\n",
    "                    if val is None or val is np.nan:\n",
    "                        has_nan = True\n",
    "                        break\n",
    "                    # Also check for float NaNs which are not identical to np.nan\n",
    "                    if isinstance(val, float) and np.isnan(val):\n",
    "                        has_nan = True\n",
    "                        break\n",
    "                \n",
    "                # 9. Write to new CSV if the row is clean\n",
    "                if not has_nan:\n",
    "                    writer.writerow(processed_row)\n",
    "                    rows_written += 1\n",
    "                    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input file {PROCESSED_FILE_PATH_CSV} not found.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during processing: {e}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Processing complete. Wrote {rows_written} valid rows to {FINAL_FILE_PATH}\")\n",
    "\n",
    "# Run the entire process\n",
    "process_and_write()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
